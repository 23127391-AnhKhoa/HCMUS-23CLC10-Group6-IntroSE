# HÆ°á»›ng Dáº«n Chi Tiáº¿t: Supabase Storage Setup Tá»« A-Z

## ğŸ¯ Má»¥c TiÃªu
HÆ°á»›ng dáº«n tá»«ng bÆ°á»›c táº¡o bucket storage trÃªn Supabase vÃ  cáº¥u hÃ¬nh code Ä‘á»ƒ upload files.

## ğŸ“‹ Tá»•ng Quan
```
Supabase Storage Flow:
1. Táº¡o Project â†’ 2. Táº¡o Bucket â†’ 3. Cáº¥u hÃ¬nh RLS â†’ 4. Setup Code â†’ 5. Test Upload
```

---

## ğŸ”° BÆ¯á»šC 1: Táº¡o Supabase Project
### 1.3 Láº¥y thÃ´ng tin káº¿t ná»‘i
```
VÃ o Settings â†’ API:

âœ… LÆ¯U Láº I 2 thÃ´ng tin nÃ y:
- Project URL: https://abcxyz123.supabase.co
- service_role key: eyJhbGciOiJIUzI1NiIs...

âš ï¸ QUAN TRá»ŒNG: DÃ¹ng service_role key, KHÃ”NG pháº£i anon key!
```

---

## ğŸ—‚ï¸ BÆ¯á»šC 2: Táº¡o Storage Bucket

### 2.1 VÃ o Storage Dashboard
```
Trong Supabase Dashboard:
1. Click "Storage" (sidebar bÃªn trÃ¡i)
2. Click "Create bucket" 
```

### 2.2 Cáº¥u hÃ¬nh bucket cÆ¡ báº£n
```
Bucket Configuration:
- Bucket name: uploads
- Public bucket: âœ… (Báº®T BUá»˜C check Ä‘á»ƒ cÃ³ public URLs)
- File size limit: 10MB (cÃ³ thá»ƒ Ä‘iá»u chá»‰nh)
- Allowed file types: Äá»ƒ trá»‘ng (accept all)

â†’ Click "Create bucket"
```

### 2.3 Táº¡o thÃªm buckets (náº¿u cáº§n)
```
Bucket "avatar":
- Name: avatar
- Public: âœ…
- Purpose: User avatars

Bucket "documents":  
- Name: documents
- Public: âŒ (private files)
- Purpose: PDFs, contracts
```

---

## ğŸ” BÆ¯á»šC 3: Cáº¥u HÃ¬nh Row Level Security (RLS)

### 3.1 Hiá»ƒu vá» Supabase Roles

**Target Roles trong Supabase:**

#### `anon` (Anonymous)
- **Ai:** NgÆ°á»i dÃ¹ng chÆ°a Ä‘Äƒng nháº­p
- **Khi nÃ o dÃ¹ng:** Cho phÃ©p upload cÃ´ng khai (khÃ´ng cáº§n Ä‘Äƒng nháº­p)
- **VÃ­ dá»¥:** Upload áº£nh trong form contact

#### `authenticated` 
- **Ai:** NgÆ°á»i dÃ¹ng Ä‘Ã£ Ä‘Äƒng nháº­p (cÃ³ JWT token)
- **Khi nÃ o dÃ¹ng:** Upload files yÃªu cáº§u Ä‘Äƒng nháº­p
- **VÃ­ dá»¥:** Upload avatar, gig images

#### `service_role`
- **Ai:** Server-side operations
- **Äáº·c Ä‘iá»ƒm:** Bá» qua táº¥t cáº£ RLS policies
- **Khi nÃ o dÃ¹ng:** Backend API, admin tasks
- **âš ï¸ Cáº£nh bÃ¡o:** KHÃ”NG bao giá» gá»­i service_role key ra client

#### `supabase_read_only_user`
- **Ai:** Role há»‡ thá»‘ng chá»‰ Ä‘á»c
- **Khi nÃ o dÃ¹ng:** Monitoring, analytics

#### `supabase_realtime_admin` & `supabase_replication_admin`
- **Ai:** Role há»‡ thá»‘ng cho realtime vÃ  replication
- **Khi nÃ o dÃ¹ng:** Ãt khi dÃ¹ng trong app thÆ°á»ng

### 3.2 Táº¡o RLS Policies

**VÃ o Database â†’ SQL Editor, cháº¡y tá»«ng policy:**

#### Policy 1: Public Read (Ai cÅ©ng xem Ä‘Æ°á»£c)
```sql
-- Cho phÃ©p má»i ngÆ°á»i xem files trong bucket "uploads"
CREATE POLICY "Public can view uploads" 
ON storage.objects 
FOR SELECT 
TO public 
USING (bucket_id = 'uploads');
```

#### Policy 2: Authenticated Upload (Pháº£i Ä‘Äƒng nháº­p má»›i upload Ä‘Æ°á»£c)
```sql
-- Chá»‰ user Ä‘Äƒng nháº­p má»›i upload Ä‘Æ°á»£c vÃ o "uploads"
CREATE POLICY "Authenticated users can upload" 
ON storage.objects 
FOR INSERT 
TO authenticated 
WITH CHECK (bucket_id = 'uploads');
```

#### Policy 3: User Can Manage Own Files
```sql
-- User chá»‰ sá»­a/xÃ³a Ä‘Æ°á»£c files cá»§a chÃ­nh mÃ¬nh
CREATE POLICY "Users can manage own files" 
ON storage.objects 
FOR ALL 
TO authenticated 
USING (auth.uid()::text = (storage.foldername(name))[1]);
```

### 3.3 Policy cho bucket "avatar"
```sql
-- Public read cho avatars
CREATE POLICY "Public can view avatars" 
ON storage.objects 
FOR SELECT 
TO public 
USING (bucket_id = 'avatar');

-- Authenticated upload cho avatars
CREATE POLICY "Users can upload avatars" 
ON storage.objects 
FOR INSERT 
TO authenticated 
WITH CHECK (bucket_id = 'avatar');
```

### 3.4 Kiá»ƒm tra RLS Ä‘Ã£ enable
```sql
-- Äáº£m báº£o RLS Ä‘Æ°á»£c báº­t
ALTER TABLE storage.objects ENABLE ROW LEVEL SECURITY;
```

---

## âš™ï¸ BÆ¯á»šC 4: Setup Backend Code

### 4.1 Táº¡o Environment File
**Táº¡o file `Backend/.env`:**
```env
# Supabase Configuration
SUPABASE_URL=https://abcxyz123.supabase.co
SUPABASE_SERVICE_KEY=eyJhbGciOiJIUzI1NiIs...

# Server Config
PORT=8000
NODE_ENV=development
```

**âš ï¸ Báº£o máº­t:**
```bash
# ThÃªm .env vÃ o .gitignore
echo ".env" >> .gitignore
```

### 4.2 Kiá»ƒm tra supabaseClient.js
**File `Backend/config/supabaseClient.js` pháº£i cÃ³:**
```javascript
const { createClient } = require('@supabase/supabase-js');
require('dotenv').config();

const supabaseUrl = process.env.SUPABASE_URL;
const supabaseKey = process.env.SUPABASE_SERVICE_KEY; // â† service_role key

if (!supabaseUrl || !supabaseKey) {
  throw new Error('Missing Supabase environment variables');
}

const supabase = createClient(supabaseUrl, supabaseKey, {
  auth: {
    persistSession: false,      // â† Server khÃ´ng cáº§n session
    autoRefreshToken: false,    // â† Server khÃ´ng cáº§n refresh
    detectSessionInUrl: false   // â† Server khÃ´ng cÃ³ URL session
  },
  db: {
    schema: 'public'
  },
  global: {
    headers: {
      'apikey': supabaseKey     // â† Äáº£m báº£o auth header
    }
  }
});

module.exports = supabase;
```

### 4.3 Táº¡o Upload Service
**File `Backend/services/upload.service.js`:**
```javascript
const supabase = require('../config/supabaseClient');

// Chá»n bucket dá»±a vÃ o purpose
const getBucketName = (purpose) => {
  switch (purpose) {
    case 'avatar': return 'avatar';
    case 'gig': return 'uploads';
    case 'document': return 'documents';
    default: return 'uploads';
  }
};

// Upload single file
const uploadFile = async (fileBuffer, fileName, folder = 'general', purpose = 'gig') => {
  const bucketName = getBucketName(purpose);
  const filePath = `${folder}/${fileName}`;
  
  console.log(`ğŸ“¤ Uploading to bucket: ${bucketName}, path: ${filePath}`);
  
  try {
    // Upload file to Supabase Storage
    const { data, error } = await supabase.storage
      .from(bucketName)
      .upload(filePath, fileBuffer, {
        contentType: 'auto', // Tá»± Ä‘á»™ng detect MIME type
        upsert: false        // KhÃ´ng ghi Ä‘Ã¨ file cÅ©
      });

    if (error) {
      console.error('âŒ Upload error:', error);
      throw new Error(`Upload failed: ${error.message}`);
    }

    // Táº¡o public URL
    const { data: urlData } = supabase.storage
      .from(bucketName)
      .getPublicUrl(filePath);

    console.log('âœ… Upload success:', urlData.publicUrl);
    
    return {
      path: data.path,
      fullPath: data.fullPath,
      url: urlData.publicUrl,
      bucket: bucketName
    };
    
  } catch (error) {
    console.error('âŒ Upload service error:', error);
    throw error;
  }
};

// Upload multiple files
const uploadMultipleFiles = async (files, folder = 'general', purpose = 'gig') => {
  const results = [];
  
  for (const file of files) {
    const timestamp = Date.now();
    const fileName = `${folder}_${timestamp}_${file.originalname}`;
    
    const result = await uploadFile(file.buffer, fileName, folder, purpose);
    results.push({
      originalName: file.originalname,
      fileName: fileName,
      size: file.size,
      mimetype: file.mimetype,
      url: result.url
    });
  }
  
  return results;
};

// Delete file
const deleteFile = async (filePath, purpose = 'gig') => {
  const bucketName = getBucketName(purpose);
  
  const { data, error } = await supabase.storage
    .from(bucketName)
    .remove([filePath]);
    
  if (error) throw error;
  return data;
};

module.exports = {
  uploadFile,
  uploadMultipleFiles,
  deleteFile,
  getBucketName
};
```

### 4.4 Táº¡o Upload Controller  
**File `Backend/controllers/upload.controller.js`:**
```javascript
const uploadService = require('../services/upload.service');

// Upload single file
const uploadSingle = async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({
        success: false,
        message: 'No file provided'
      });
    }

    const { folder = 'general', purpose = 'gig' } = req.body;
    const timestamp = Date.now();
    const fileName = `${folder}_${timestamp}_${req.file.originalname}`;

    const result = await uploadService.uploadFile(
      req.file.buffer,
      fileName,
      folder,
      purpose
    );

    res.json({
      success: true,
      file: {
        originalName: req.file.originalname,
        fileName: fileName,
        size: req.file.size,
        mimetype: req.file.mimetype,
        url: result.url,
        bucket: result.bucket
      },
      message: 'File uploaded successfully'
    });

  } catch (error) {
    console.error('âŒ Upload controller error:', error);
    res.status(500).json({
      success: false,
      message: error.message
    });
  }
};

// Upload multiple files
const uploadMultiple = async (req, res) => {
  try {
    if (!req.files || req.files.length === 0) {
      return res.status(400).json({
        success: false,
        message: 'No files provided'
      });
    }

    const { folder = 'general', purpose = 'gig' } = req.body;
    
    const results = await uploadService.uploadMultipleFiles(
      req.files,
      folder,
      purpose
    );

    res.json({
      success: true,
      files: results,
      message: `${results.length} files uploaded successfully`
    });

  } catch (error) {
    console.error('âŒ Multiple upload error:', error);
    res.status(500).json({
      success: false,
      message: error.message
    });
  }
};

module.exports = {
  uploadSingle,
  uploadMultiple
};
```

### 4.5 Cáº¥u hÃ¬nh Routes
**File `Backend/routes/upload.routes.js`:**
```javascript
const express = require('express');
const multer = require('multer');
const uploadController = require('../controllers/upload.controller');

const router = express.Router();

// Multer configuration
const storage = multer.memoryStorage(); // LÆ°u file trong memory
const upload = multer({
  storage: storage,
  limits: {
    fileSize: 10 * 1024 * 1024, // 10MB limit
    files: 10                    // Max 10 files
  },
  fileFilter: (req, file, cb) => {
    // Kiá»ƒm tra file types
    const allowedTypes = [
      'image/jpeg', 'image/png', 'image/gif', 'image/webp',
      'video/mp4', 'video/avi', 'video/mov',
      'application/pdf', 'application/msword'
    ];
    
    if (allowedTypes.includes(file.mimetype)) {
      cb(null, true);
    } else {
      cb(new Error('File type not allowed'), false);
    }
  }
});

// Routes
router.post('/single', upload.single('file'), uploadController.uploadSingle);
router.post('/multiple', upload.array('files', 10), uploadController.uploadMultiple);

module.exports = router;
```

### 4.6 ÄÄƒng kÃ½ Routes trong App
**File `Backend/server.js` hoáº·c `Backend/app.js`:**
```javascript
const express = require('express');
const uploadRoutes = require('./routes/upload.routes');

const app = express();

// Middleware
app.use(express.json());
app.use(express.urlencoded({ extended: true }));

// Routes
app.use('/api/upload', uploadRoutes);

// Error handling
app.use((error, req, res, next) => {
  if (error instanceof multer.MulterError) {
    if (error.code === 'LIMIT_FILE_SIZE') {
      return res.status(400).json({
        success: false,
        message: 'File too large (max 10MB)'
      });
    }
  }
  
  res.status(500).json({
    success: false,
    message: error.message
  });
});

const PORT = process.env.PORT || 8000;
app.listen(PORT, () => {
  console.log(`ğŸš€ Server running on port ${PORT}`);
});
```

---

## ğŸ§ª BÆ¯á»šC 5: Testing & Verification

### 5.1 Test Connection
```bash
cd Backend

# Test 1: Check environment variables
node -e "
console.log('âœ… URL:', process.env.SUPABASE_URL);
console.log('âœ… KEY:', process.env.SUPABASE_SERVICE_KEY?.substring(0, 20) + '...');
"

# Test 2: Check bucket connection
node -e "
const supabase = require('./config/supabaseClient');
supabase.storage.listBuckets().then(({data, error}) => {
  if (error) console.log('âŒ Error:', error);
  else console.log('âœ… Buckets:', data.map(b => b.name));
});
"
```

### 5.2 Test Upload
```bash
# Táº¡o test file
echo "const supabase = require('./config/supabaseClient');
const test = async () => {
  console.log('ğŸ§ª Testing upload...');
  
  const content = Buffer.from('Hello Supabase Storage!');
  const fileName = \`test_\${Date.now()}.txt\`;
  const filePath = \`test/\${fileName}\`;
  
  try {
    // Upload
    const { data, error } = await supabase.storage
      .from('uploads')
      .upload(filePath, content);
      
    if (error) throw error;
    
    // Get public URL
    const { data: urlData } = supabase.storage
      .from('uploads')
      .getPublicUrl(filePath);
      
    console.log('âœ… Upload successful!');
    console.log('ğŸ“ Path:', data.path);
    console.log('ğŸ”— URL:', urlData.publicUrl);
    
    // Test URL accessibility
    const response = await fetch(urlData.publicUrl);
    if (response.ok) {
      console.log('âœ… URL is accessible');
    } else {
      console.log('âŒ URL not accessible');
    }
    
    // Cleanup
    await supabase.storage.from('uploads').remove([filePath]);
    console.log('ğŸ§¹ Cleanup completed');
    
  } catch (error) {
    console.error('âŒ Test failed:', error);
  }
};
test();" > test-upload.js

node test-upload.js
```

### 5.3 Test API Endpoints
```bash
# Test single upload (cÃ³ file image.jpg trong thÆ° má»¥c)
curl -X POST http://localhost:8000/api/upload/single \
  -F "file=@image.jpg" \
  -F "folder=test" \
  -F "purpose=gig"

# Test multiple upload
curl -X POST http://localhost:8000/api/upload/multiple \
  -F "files=@image1.jpg" \
  -F "files=@image2.jpg" \
  -F "folder=gallery" \
  -F "purpose=gig"
```

### 5.4 Verification Checklist
```
âœ… Environment Setup:
- [ ] .env file cÃ³ SUPABASE_URL
- [ ] .env file cÃ³ SUPABASE_SERVICE_KEY
- [ ] .env Ä‘Æ°á»£c thÃªm vÃ o .gitignore

âœ… Supabase Dashboard:
- [ ] Project Ä‘Æ°á»£c táº¡o thÃ nh cÃ´ng
- [ ] Bucket "uploads" tá»“n táº¡i vÃ  public
- [ ] RLS policies Ä‘Æ°á»£c táº¡o

âœ… Backend Code:
- [ ] supabaseClient.js káº¿t ná»‘i thÃ nh cÃ´ng
- [ ] Upload service hoáº¡t Ä‘á»™ng
- [ ] API endpoints response Ä‘Ãºng

âœ… Testing:
- [ ] listBuckets() tráº£ vá» danh sÃ¡ch buckets
- [ ] Upload test file thÃ nh cÃ´ng
- [ ] Public URL accessible
- [ ] Cleanup hoáº¡t Ä‘á»™ng
```

---

## ğŸ¯ Káº¿t Quáº£ Cuá»‘i CÃ¹ng

### URL Structure
```
Bucket "uploads":
https://abcxyz123.supabase.co/storage/v1/object/public/uploads/folder/filename.jpg

Bucket "avatar":
https://abcxyz123.supabase.co/storage/v1/object/public/avatar/profiles/user123.jpg
```

### API Usage
```javascript
// Frontend upload
const formData = new FormData();
formData.append('file', file);
formData.append('folder', 'gigs');
formData.append('purpose', 'gig');

const response = await fetch('/api/upload/single', {
  method: 'POST',
  body: formData
});

const result = await response.json();
console.log('Upload URL:', result.file.url);
```

### File Organization
```
uploads/
â”œâ”€â”€ gigs/
â”‚   â”œâ”€â”€ gigs_1641234567_cover.jpg
â”‚   â””â”€â”€ gigs_1641234568_gallery.jpg
â”œâ”€â”€ avatars/
â”‚   â”œâ”€â”€ avatars_1641234569_user123.jpg
â”‚   â””â”€â”€ avatars_1641234570_user456.png
â””â”€â”€ temp/
    â””â”€â”€ temp_1641234571_file.jpg
```

---

## ğŸš¨ Troubleshooting

### Lá»—i thÆ°á»ng gáº·p:

#### "Invalid API key"
```bash
# Check key type
node -e "
const key = process.env.SUPABASE_SERVICE_KEY;
if (key.includes('eyJ')) console.log('âœ… Valid JWT format');
else console.log('âŒ Invalid key format');
"
```

#### "Bucket not found"
```sql
-- Check buckets in SQL Editor
SELECT name, public FROM storage.buckets;
```

#### "RLS policy violation"
```sql
-- Temporarily disable RLS for testing
ALTER TABLE storage.objects DISABLE ROW LEVEL SECURITY;
-- Remember to enable again after testing
-- ALTER TABLE storage.objects ENABLE ROW LEVEL SECURITY;
```

#### "CORS error"
- Äáº£m báº£o bucket lÃ  public âœ…
- Check frontend origin trong Supabase settings

---

**ğŸ‰ HoÃ n thÃ nh! Storage system Ä‘Ã£ sáºµn sÃ ng upload files!**
